{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d27ecd49",
   "metadata": {},
   "source": [
    "Conversation Management & JSON Extraction (Groq/OpenAI-compatible)\n",
    "Author: Ayush Rai\n",
    "Date: 2025-09-13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91aa9b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-1.107.2-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting jsonschema\n",
      "  Using cached jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\ayush\\onedrive\\desktop\\evrything\\workspace\\pandas\\venv\\lib\\site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\ayush\\onedrive\\desktop\\evrything\\workspace\\pandas\\venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ayush\\onedrive\\desktop\\evrything\\workspace\\pandas\\venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\ayush\\onedrive\\desktop\\evrything\\workspace\\pandas\\venv\\lib\\site-packages (from openai) (0.11.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\ayush\\onedrive\\desktop\\evrything\\workspace\\pandas\\venv\\lib\\site-packages (from openai) (2.11.9)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ayush\\onedrive\\desktop\\evrything\\workspace\\pandas\\venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\ayush\\onedrive\\desktop\\evrything\\workspace\\pandas\\venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\ayush\\onedrive\\desktop\\evrything\\workspace\\pandas\\venv\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\ayush\\onedrive\\desktop\\evrything\\workspace\\pandas\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\ayush\\onedrive\\desktop\\evrything\\workspace\\pandas\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ayush\\onedrive\\desktop\\evrything\\workspace\\pandas\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\ayush\\onedrive\\desktop\\evrything\\workspace\\pandas\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ayush\\onedrive\\desktop\\evrything\\workspace\\pandas\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\ayush\\onedrive\\desktop\\evrything\\workspace\\pandas\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\ayush\\onedrive\\desktop\\evrything\\workspace\\pandas\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\ayush\\onedrive\\desktop\\evrything\\workspace\\pandas\\venv\\lib\\site-packages (from jsonschema) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\ayush\\onedrive\\desktop\\evrything\\workspace\\pandas\\venv\\lib\\site-packages (from jsonschema) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\ayush\\onedrive\\desktop\\evrything\\workspace\\pandas\\venv\\lib\\site-packages (from jsonschema) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\ayush\\onedrive\\desktop\\evrything\\workspace\\pandas\\venv\\lib\\site-packages (from jsonschema) (0.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ayush\\onedrive\\desktop\\evrything\\workspace\\pandas\\venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Using cached openai-1.107.2-py3-none-any.whl (946 kB)\n",
      "Using cached jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Installing collected packages: openai, jsonschema\n",
      "\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   ---------------------------------------- 0/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [jsonschema]\n",
      "   -------------------- ------------------- 1/2 [jsonschema]\n",
      "   -------------------- ------------------- 1/2 [jsonschema]\n",
      "   -------------------- ------------------- 1/2 [jsonschema]\n",
      "   -------------------- ------------------- 1/2 [jsonschema]\n",
      "   -------------------- ------------------- 1/2 [jsonschema]\n",
      "   -------------------- ------------------- 1/2 [jsonschema]\n",
      "   ---------------------------------------- 2/2 [jsonschema]\n",
      "\n",
      "Successfully installed jsonschema-4.25.1 openai-1.107.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\ayush\\OneDrive\\Desktop\\Evrything\\Workspace\\Pandas\\venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\ayush\\OneDrive\\Desktop\\Evrything\\Workspace\\Pandas\\venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\ayush\\OneDrive\\Desktop\\Evrything\\Workspace\\Pandas\\venv\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai jsonschema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f91c84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.environ.get(\"GROQ_API_KEY\")\n",
    "if not GROQ_API_KEY:\n",
    "    print(\"WARNING: GROQ_API_KEY not set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4014d5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def make_groq_client():\n",
    "    api_key = os.environ.get(\"GROQ_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise RuntimeError(\"Please set the GROQ_API_KEY environment variable before calling the API.\")\n",
    "    # The OpenAI Python client can be constructed by setting api_key and base_url:\n",
    "    client = openai.OpenAI(api_key=api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "    return client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f1dfea",
   "metadata": {},
   "source": [
    "Task 1: Conversation Management & Summarization\n",
    "\n",
    "Implementation notes:\n",
    "Summarization uses the LLM.\n",
    "After every k-th 'run', replace older history with the summary according to rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83e6a498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "class ConversationManager:\n",
    "    def __init__(self, client=None, system_prompt=None):\n",
    "        self.history: List[Dict[str, Any]] = []\n",
    "        self.client = client\n",
    "        self.system_prompt = system_prompt or \"You are an assistant.\"\n",
    "        if self.system_prompt:\n",
    "            self.history.append({\"role\": \"system\", \"content\": self.system_prompt})\n",
    "        self.run_count = 0\n",
    "\n",
    "    def append_message(self, role: str, content: str, meta: dict=None):\n",
    "        if meta is None:\n",
    "            meta = {}\n",
    "        self.history.append({\"role\": role, \"content\": content, \"meta\": meta})\n",
    "\n",
    "    def _last_n_turns(self, n:int) -> List[Dict[str,str]]:\n",
    "        msgs = self.history[1:] if self.history and self.history[0]['role']=='system' else self.history\n",
    "        return msgs[-(2*n):] if n>0 else []\n",
    "\n",
    "    def truncate_by_turns(self, n:int):\n",
    "        sys = [self.history[0]] if self.history and self.history[0]['role']=='system' else []\n",
    "        kept = self._last_n_turns(n)\n",
    "        self.history = sys + kept\n",
    "\n",
    "    def truncate_by_chars(self, max_chars:int):\n",
    "        sys = [self.history[0]] if self.history and self.history[0]['role']=='system' else []\n",
    "        msgs = self.history[1:] if sys else self.history[:]\n",
    "        total = 0\n",
    "        kept = []\n",
    "        # iterate reversed to keep recent\n",
    "        for m in reversed(msgs):\n",
    "            l = len(m['content'])\n",
    "            if total + l > max_chars and kept:\n",
    "                break\n",
    "            kept.append(m)\n",
    "            total += l\n",
    "        kept.reverse()\n",
    "        self.history = sys + kept\n",
    "\n",
    "    def get_history_text(self):\n",
    "        return \"\\n\".join([f\"{m['role']}: {m['content']}\" for m in self.history])\n",
    "\n",
    "    def summarize_history(self, client, max_output_tokens=512):\n",
    "        if not client:\n",
    "            raise RuntimeError(\"Client not provided for summarization.\")\n",
    "\n",
    "        messages = [\n",
    "            {\"role\":\"system\", \"content\": \"You are an expert summarizer. Produce a concise summary (1-3 sentences) capturing key user intents and facts. Output only the summary.\"},\n",
    "            {\"role\":\"user\", \"content\": \"Summarize the conversation below:\\n\\n\" + self.get_history_text()}\n",
    "        ]\n",
    "        # Use chat completion\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"openai/gpt-oss-20b\", \n",
    "            messages=messages,\n",
    "            max_tokens=max_output_tokens,\n",
    "            temperature=0.1\n",
    "        )\n",
    "        summary_text = resp.choices[0].message.content.strip()\n",
    "        return summary_text\n",
    "\n",
    "    def periodic_summarize_and_replace(self, client, k:int, keep_recent_turns:int=2):\n",
    "        if k <= 0:\n",
    "            return None\n",
    "        if (self.run_count > 0) and (self.run_count % k == 0):\n",
    "            summary = self.summarize_history(client)\n",
    "            # Build new history: system + summary (assistant) + last keep_recent_turns turns\n",
    "            sys = [self.history[0]] if self.history and self.history[0]['role']=='system' else []\n",
    "            tmp_mgr = ConversationManager(system_prompt=None)\n",
    "            tmp_mgr.history = self.history.copy()\n",
    "            recent = tmp_mgr._last_n_turns(keep_recent_turns)\n",
    "            self.history = sys + [{\"role\":\"assistant\",\"content\":f\"[Summary]: {summary}\"}] + recent\n",
    "            return summary\n",
    "        return None\n",
    "\n",
    "    def run_one_step(self, user_input:str, client, do_summary_every_k:int=3):\n",
    "        self.append_message(\"user\", user_input)\n",
    "        # build messages for LLM from current history\n",
    "        messages = [{\"role\":m[\"role\"], \"content\":m[\"content\"]} for m in self.history]\n",
    "        messages.append({\"role\":\"user\", \"content\":user_input}) \n",
    "\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"openai/gpt-oss-20b\",\n",
    "            messages=messages,\n",
    "            max_tokens=256,\n",
    "            temperature=0.2\n",
    "        )\n",
    "        assistant_text = resp.choices[0].message.content.strip()\n",
    "        self.append_message(\"assistant\", assistant_text)\n",
    "        self.run_count += 1\n",
    "\n",
    "        summary = self.periodic_summarize_and_replace(client, k=do_summary_every_k, keep_recent_turns=2)\n",
    "        return assistant_text, summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246a47ee",
   "metadata": {},
   "source": [
    "Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d343892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Demo: periodic summarization after every 3 runs ===\n",
      "\n",
      "--- Run 1 ---\n",
      "User: Hi, I want to book a flight from Bangalore to Delhi next month.\n",
      "Assistant: Assistant reply to: Hi, I want to book a flight from Bangalore to Delhi next month.\n",
      "History now:\n",
      "system: System: You are a helpful assistant.\n",
      "user: Hi, I want to book a flight from Bangalore to Delhi next month.\n",
      "assistant: Assistant reply to: Hi, I want to book a flight from Bangalore to Delhi next month.\n",
      "\n",
      "--- Run 2 ---\n",
      "User: Actually date changed to Oct 25, preference evening flight.\n",
      "Assistant: Assistant reply to: Actually date changed to Oct 25, preference evening flight.\n",
      "History now:\n",
      "system: System: You are a helpful assistant.\n",
      "user: Hi, I want to book a flight from Bangalore to Delhi next month.\n",
      "assistant: Assistant reply to: Hi, I want to book a flight from Bangalore to Delhi next month.\n",
      "user: Actually date changed to Oct 25, preference evening flight.\n",
      "assistant: Assistant reply to: Actually date changed to Oct 25, preference evening flight.\n",
      "\n",
      "--- Run 3 ---\n",
      "User: I also need a hotel near Connaught Place.\n",
      "Assistant: Assistant reply to: I also need a hotel near Connaught Place.\n",
      "PERIODIC SUMMARY CREATED:\n",
      " Assistant reply to: Summarize the conversation below:\n",
      "\n",
      "system: System: You are a helpful assistant.\n",
      "History now:\n",
      "system: System: You are a helpful assistant.\n",
      "assistant: [Summary]: Assistant reply to: Summarize the conversation below:\n",
      "\n",
      "system: System: You are a helpful assistant.\n",
      "user: Actually date changed to Oct 25, preference evening flight.\n",
      "assistant: Assistant reply to: Actually date changed to Oct 25, preference evening flight.\n",
      "user: I also need a hotel near Connaught Place.\n",
      "assistant: Assistant reply to: I also need a hotel near Connaught Place.\n",
      "\n",
      "--- Run 4 ---\n",
      "User: Add dietary preference: vegetarian meals.\n",
      "Assistant: Assistant reply to: Add dietary preference: vegetarian meals.\n",
      "History now:\n",
      "system: System: You are a helpful assistant.\n",
      "assistant: [Summary]: Assistant reply to: Summarize the conversation below:\n",
      "\n",
      "system: System: You are a helpful assistant.\n",
      "user: Actually date changed to Oct 25, preference evening flight.\n",
      "assistant: Assistant reply to: Actually date changed to Oct 25, preference evening flight.\n",
      "user: I also need a hotel near Connaught Place.\n",
      "assistant: Assistant reply to: I also need a hotel near Connaught Place.\n",
      "user: Add dietary preference: vegetarian meals.\n",
      "assistant: Assistant reply to: Add dietary preference: vegetarian meals.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class DummyClient:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    class chat:\n",
    "        class completions:\n",
    "            @staticmethod\n",
    "            def create(model, messages, max_tokens=256, temperature=0.2):\n",
    "                last_user = [m for m in messages if m['role']=='user'][-1]['content']\n",
    "                if \"Summarize the conversation below:\" in messages[0]['content']:\n",
    "                    text = messages[1]['content'].split(\"Summarize the conversation below:\\n\\n\")[-1]\n",
    "                    s = (\"Summary: \" + text[:120].replace(\"\\n\", \" \") + \"...\").strip()\n",
    "                    class R: pass\n",
    "                    R.choices = [type(\"C\",(object,),{\"message\":type(\"M\",(object,),{\"content\":s})})()]\n",
    "                    return R()\n",
    "                else:\n",
    "                    reply = f\"Assistant reply to: {last_user[:80]}\"\n",
    "                    class R: pass\n",
    "                    R.choices = [type(\"C\",(object,),{\"message\":type(\"M\",(object,),{\"content\":reply})})()]\n",
    "                    return R()\n",
    "\n",
    "dm = ConversationManager(system_prompt=\"System: You are a helpful assistant.\")\n",
    "dummy_client = DummyClient()\n",
    "runs = [\n",
    "    \"Hi, I want to book a flight from Bangalore to Delhi next month.\",\n",
    "    \"Actually date changed to Oct 25, preference evening flight.\",\n",
    "    \"I also need a hotel near Connaught Place.\",\n",
    "    \"Add dietary preference: vegetarian meals.\"\n",
    "]\n",
    "\n",
    "print(\"=== Demo: periodic summarization after every 3 runs ===\")\n",
    "for i, u in enumerate(runs, start=1):\n",
    "    assistant_text, summary = dm.run_one_step(u, client=dummy_client, do_summary_every_k=3)\n",
    "    print(f\"\\n--- Run {i} ---\")\n",
    "    print(\"User:\", u)\n",
    "    print(\"Assistant:\", assistant_text)\n",
    "    if summary:\n",
    "        print(\"PERIODIC SUMMARY CREATED:\\n\", summary)\n",
    "    print(\"History now:\")\n",
    "    print(dm.get_history_text())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a98ec91",
   "metadata": {},
   "source": [
    "Task 2: JSON Schema Classification & Function-calling style extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6834fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from jsonschema import validate, ValidationError\n",
    "\n",
    "# JSON Schema\n",
    "user_info_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"name\": {\"type\":\"string\"},\n",
    "        \"email\": {\"type\": \"string\", \"format\":\"email\"},\n",
    "        \"phone\": {\"type\": \"string\", \"pattern\": \"^[0-9\\\\+\\\\-\\\\(\\\\)\\\\s]{7,20}$\"},\n",
    "        \"location\": {\"type\":\"string\"},\n",
    "        \"age\": {\"type\":\"integer\", \"minimum\":0, \"maximum\":150}\n",
    "    },\n",
    "    \"required\": [\"name\", \"email\"],\n",
    "    \"additionalProperties\": False\n",
    "}\n",
    "\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"extract_user_info\",\n",
    "        \"description\": \"Extract user contact and basic demographics from chat.\",\n",
    "        \"parameters\": user_info_schema\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# Sample\n",
    "sample_chats = [\n",
    "    \"Hi, I'm Ayush Rai. You can reach me at ayushrai@gmail.com or +91-9876543210. I'm 22 and live in Lucknow.\",\n",
    "    \"Hello - name: Aisha Khan, email: aisha.k@example.org; phone (555) 203-9988. Location: New Delhi. Age: 29.\",\n",
    "    \"Hey, it's John. Email john_doe@nomail. I don't want to give phone. I'm 32 from Bangalore.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f88c9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def call_extract_function(client, chat_text, model=\"openai/gpt-oss-20b\"):\n",
    "\n",
    "    messages = [\n",
    "        {\"role\":\"system\", \"content\": \"You are an extraction agent. Strictly return JSON matching the function schema.\"},\n",
    "        {\"role\":\"user\", \"content\": chat_text}\n",
    "    ]\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        function_call={\"name\":\"extract_user_info\"},\n",
    "        max_tokens=300,\n",
    "        temperature=0.0\n",
    "    )\n",
    "    \n",
    "    choice = resp.choices[0]\n",
    "    fc = getattr(choice.message, \"function_call\", None)\n",
    "    if fc is None:\n",
    "        raw = choice.message.content.strip()\n",
    "        try:\n",
    "            data = json.loads(raw)\n",
    "            return data\n",
    "        except Exception:\n",
    "            raise ValueError(\"Model didn't return valid JSON for function args.\")\n",
    "    else:\n",
    "        args_text = fc.get(\"arguments\") if isinstance(fc, dict) else fc.arguments\n",
    "        try:\n",
    "            data = json.loads(args_text)\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            raise ValueError(\"Failed to parse function arguments JSON: \" + str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c197134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample 1 ---\n",
      "Extracted: {'age': 24, 'email': 'rahul.sharma@email.com', 'location': 'Pune', 'name': 'Rahul Sharma', 'phone': '+91-9876543210'}\n",
      "✅ Schema validation passed\n",
      "\n",
      "--- Sample 2 ---\n",
      "Extracted: {'age': 29, 'email': 'aisha.k@example.org', 'location': 'New Delhi', 'name': 'Aisha Khan', 'phone': '(555) 203-9988'}\n",
      "✅ Schema validation passed\n",
      "\n",
      "--- Sample 3 ---\n",
      "Extracted: {'age': 32, 'email': 'john_doe@nomail', 'location': 'Bangalore', 'name': 'John'}\n",
      "✅ Schema validation passed\n"
     ]
    }
   ],
   "source": [
    "client = make_groq_client()\n",
    "\n",
    "for idx, chat in enumerate(sample_chats, start=1):\n",
    "    print(f\"\\n--- Sample {idx} ---\")\n",
    "    try:\n",
    "        extracted = call_extract_function(client, chat, model=\"openai/gpt-oss-20b\") \n",
    "        print(\"Extracted:\", extracted)\n",
    "        \n",
    "        # Validate\n",
    "        validate(instance=extracted, schema=user_info_schema)\n",
    "        print(\"✅ Schema validation passed\")\n",
    "    except ValidationError as ve:\n",
    "        print(\"❌ Schema validation failed:\", ve.message)\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ Extraction error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc25c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
